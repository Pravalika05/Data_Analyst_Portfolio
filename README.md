# Data-Analytics-Projects:
 

preparing myself for career as a data analyst by helping me learn to clean and organize data,
uncover patterns and insights, draw meaningful conclusions, and clearly communicate critical findings. I am developing proficiency
in Python and its data analysis libraries (Numpy, pandas, Matplotlib) and SQL as I build a portfolio of projects .

Tips: For data science projects with python, I would recomend you to install numpy , pandas , scipy , scikit learn , matplotlib , 
seaborn thest basic libraries. 


## Part 1 - Intro to Data Analysis

Subjects Covered:
* Jupyter Notebook: Learn to use this open-source web application 
* Data Analysis Process
* NumPy , Pandas , Dataframes for 1 and 2D Data

### Project 1:  Investigate a dataset called TMDb Movie data.
I used statistical techniques to find answers about the data and report my conclusions and recommendations in a report. In this project, I choose one of datasets and investigate it using NumPy and pandas.I complete the entire data analysis process, and finishing by sharing the findings. 

### Project 2: Data Analysis with Nigeria Covid 19 data.




## Part 2 - Practical Statistics 

Subjects Covered:
* Probability
* Conditional Probability
* Binominal Distribution
* Sampling Distribution and Central Limit Theorem
* Descriptive Statistics
* Inferential Statistics
* Confidence Levels and Intervals
* Hypothesis Testing
* T-tests and A/B test
* Regression
* Multiple Linear Regression
* Logistic Regression

### Project 3 : Analyze A/B Test Results with company ab_data.csv 
I used Python to collect data from different places and then cleaned it to ensure it was in good shape. I recorded all these steps in a Jupyter Notebook. Then, I used Python and SQL to analyze the data and create visualizations. I also used AB Testing and regression techniques to help the company decide if they should introduce a new webpage or stick with the current one. 




## Part 3 - Data Extraction and Wrangling

Subjects Covered:
* GATHERING DATA: 
   * Gather data from multiple sources, including gathering files, programmatically downloading files, web-scraping data, 
     and accessing data from APIs
   * Import data of various file formats into pandas, including flat files (e.g. TSV), HTML files, TXT files, and JSON files
   * Store gathered data in a PostgreSQL database
* ASSESSING DATA 
   * Assess data visually and programmatically using pandas
   * Distinguish between dirty data (content or “quality” issues) and messy data (structural or “tidiness” issues)
   * Identify data quality issues and categorize them using metrics: validity, accuracy, completeness, consistency, and uniformity
* CLEANING DATA 
   * Identify each step of the data cleaning process (defining, coding,and testing)
   * Clean data using Python and pandas
   * Test cleaning code visually and programmatically using Python
   
### Project 4 : Case Study in Data Wrangling.
I split this project into three steps: collecting the data, checking it, and cleaning it up. The data I used was quite messy. I first identified the problems with it and found three main issues: missing values, disorderliness, and quality concerns. I tackled these problems one by one, and by the end, I had tidy and accurate data. I did all the cleaning in a Jupyter Notebook using tools called pandas and numpy.





## Part 4 - Data Visualization

Covered various Visualizations:
* Univariate exploration of data ( histogram , bar charts , Use axis limits and different scales ) 
* Bivariate exploration of data ( scatter plots , clustered bar charts , violin and bar charts , faceting )
* Multivariate exploration of data ( encodings , plot matrices , feature enginnering )
* Explanatory Visulizations ( story telling with data ,  polish plots , create slide deck ) 

### Project 5: Data Visulization with Diamond Data
Data visualization to a dataset involving the characteristics of diamonds and their prices.

### Project 6: Data Visualization with Prosper Loan data.
Perform Explanatory and Exploratory Data Analysis on Prosper Loan Data.










